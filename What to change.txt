üéØ EXAM QUICK REFERENCE ‚Äî What To Change

TASK 1: RAG PIPELINE
ingest.py (Run FIRST)
DATA_DIR = 'data'              ‚Üê Folder with .txt files
EMBEDDING_MODEL = 'nomic-embed-text'  ‚Üê Or 'llama3.1'
CHUNK_SIZE = 2000              ‚Üê Characters per chunk
CHUNK_OVERLAP = 50             ‚Üê Overlap between chunks
rag_chain.py (Run SECOND)
EMBEDDING_MODEL = '...'        ‚Üê MUST MATCH ingest.py!
LLM_MODEL = 'llama3.1'         ‚Üê Model for answers
NUM_RESULTS = 3                ‚Üê How many chunks to find
question = "..."               ‚Üê YOUR QUESTION HERE
‚ö†Ô∏è IMPORTANT: EMBEDDING_MODEL must be SAME in both files!

TASK 2: BLIP
blip_caption.py
IMAGE_PATH = r"images/test.jpg"    ‚Üê YOUR IMAGE PATH
TEXT_PROMPT = "a photo of"         ‚Üê For conditional caption
QUESTION = "What is in the image?" ‚Üê For Q&A

NOTHING ELSE CHANGES!
All imports, functions, logic ‚Äî keep exactly as is.

EXAM STEPS
RAG:

Put .txt files in data/ folder
Run python ingest.py
Change question in rag_chain.py
Run python rag_chain.py

BLIP:

Change IMAGE_PATH to your image
Run python blip_caption.py


COMMON MISTAKES TO AVOID
‚ùå Don't name file ollama.py
‚ùå Don't forget to run ollama serve
‚ùå Don't use different EMBEDDING_MODEL in two files
‚ùå Don't forget r"" for Windows paths